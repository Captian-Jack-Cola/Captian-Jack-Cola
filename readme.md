<!-- Banner -->
<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=rect&color=FF3300&height=4&section=header&text=&fontSize=0" alt="">
</p>

<h1 align="center">ğŸ”¥ Pushing servers to the fiery limit</h1>
<p align="center">
  I tune systems until the racks sweat.
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Focus-High%20Performance%20%26%20Reliability-FF6B00">
  <img src="https://img.shields.io/badge/Works%20With-Linux%20%7C%20K8s%20%7C%20Cloud-FF3300">
  <img src="https://img.shields.io/badge/Motto-Run%20Hot%2C%20Run%20Right-FFD166">
</p>

---

### ğŸ”¥ What I do
- Scale services until they **purr under load**
- Squeeze latency to **sub-millisecond sparks**
- Automate deployments that **ignite** fast and safely

### âš™ï¸ Tools of the trade
`SaltStack` Â· `Elasticsearch` Â· `Terraform`  
`Redis` Â· `Ansible` Â· `Cassandra` Â· `Kubernetes` Â· `Splunk`  
`OpenSSL` Â· `Nginx`  
`Flask` Â· `Istio` Â· `RabbitMQ` Â· `Envoy`

### ğŸ“ˆ Recent heat
- Cut p99 latency by **42%** with adaptive caching
- Saved **30%** infra cost via right-sizing + spot strategy
- 0->1 multi-region rollout with automated failover

---

### ğŸ”¥ Featured repos
- **blaze-proxy** â€” event-driven edge proxy with zero-copy I/O  
- **ember-operator** â€” K8s operator for safe, scorched-earth rollouts  
- **cinder-cache** â€” lock-free, write-through cache with TTL fusion

---

### ğŸ§ª Bench sparks (sample)
```bash
hey -z 30s -c 200 https://api.yourservice.dev
# Aim: >150k rps, p99 < 12ms, errors < 0.1%
